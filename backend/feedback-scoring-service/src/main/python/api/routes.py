from fastapi import APIRouter, HTTPException, Query, Request, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Optional
import logging
import traceback
import os
from datetime import datetime

from models.feedback_analysis import *
from core.scoring_model import FeedbackScorer
from services import FeedbackAnalyzerService
import core.train_model as train_model
from config.settings import MODEL_DIR, MONGODB_URL, FEEDBACK_SERVICE_URL
from utils.helpers import async_timed, normalize_score

# Get logger
logger = logging.getLogger(__name__)

# Create API router
router = APIRouter()

# Initialize feedback scorer
scorer = FeedbackScorer(model_path=MODEL_DIR)

# Initialize feedback analyzer service
feedback_analyzer = FeedbackAnalyzerService(
    mongodb_url=MONGODB_URL,
    feedback_service_url=FEEDBACK_SERVICE_URL
)

@router.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # Test the model by scoring a simple text
        test_result = scorer.score_text_based("This is a test message")
        return {
            "status": "healthy",
            "service": "feedback-scoring",
            "model_status": "loaded"
        }
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "service": "feedback-scoring",
                "model_status": "error",
                "error": str(e)
            }
        )

@router.post("/api/score")
@async_timed
async def score_feedback(submission: dict):
    """Score a feedback submission"""
    try:
        logger.info(f"Scoring feedback submission: {submission.get('id')}")
        result = scorer.score_submission(submission, submission.get("questions", []))
        return result
    except Exception as e:
        logger.error(f"Error scoring feedback: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error scoring feedback: {str(e)}"
        )

@router.post("/api/analyze/text")
@async_timed
async def analyze_text(text: str):
    """Analyze a text response"""
    try:
        logger.info("Analyzing text response")
        result = await feedback_analyzer.text_analyzer.analyze_text_response(text)
        return result
    except Exception as e:
        logger.error(f"Error analyzing text: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error analyzing text: {str(e)}"
        )

@router.post("/api/retrain")
async def retrain_model(background_tasks: BackgroundTasks):
    """Retrain the model with new data"""
    try:
        logger.info("Starting model retraining")
        background_tasks.add_task(train_model.main)
        return {"message": "Model retraining started in background"}
    except Exception as e:
        logger.error(f"Error starting model retraining: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error starting model retraining: {str(e)}"
        )

@router.get("/api/submissions/all")
@async_timed
async def get_all_submissions():
    """Get all feedback submissions with their scores and analysis"""
    try:
        logger.info("Fetching and analyzing all feedback submissions")
        
        # Fetch submissions
        submissions = await feedback_analyzer.data_service.fetch_all_submissions()
        logger.info(f"Retrieved {len(submissions)} submissions")
        
        # Analyze each submission
        analyzed_submissions = []
        for submission in submissions:
            try:
                logger.info(f"Analyzing submission {submission.get('id')}")
                analysis = await feedback_analyzer.analyze_feedback_submission(submission)
                logger.info(f"Successfully analyzed submission {submission.get('id')}")
                
                analyzed_submissions.append({
                    "submission": submission,
                    "analysis": analysis.dict(),
                    "error": None
                })
            except Exception as e:
                logger.error(f"Error analyzing submission {submission.get('id')}: {str(e)}")
                logger.error(f"Error details: {e.__class__.__name__}: {str(e)}")
                analyzed_submissions.append({
                    "submission": submission,
                    "analysis": None,
                    "error": str(e)
                })
        
        return analyzed_submissions
    except Exception as e:
        logger.error(f"Error processing submissions: {str(e)}")
        logger.error(f"Error details: {e.__class__.__name__}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error processing submissions: {str(e)}"
        )

@router.get("/api/analysis/feedback/{feedback_id}")
@async_timed
async def get_feedback_analysis(feedback_id: int):
    """Get analysis for a specific feedback"""
    try:
        logger.info(f"Analyzing feedback ID: {feedback_id}")
        
        # Fetch submissions for this feedback ID
        submissions = await feedback_analyzer.data_service.fetch_submissions_by_feedback_id(feedback_id)
        
        if not submissions:
            logger.warning(f"No submissions found for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=404,
                detail=f"No submissions found for feedback ID: {feedback_id}"
            )
        
        # Analyze each submission
        analyses = []
        for submission in submissions:
            try:
                analysis = await feedback_analyzer.analyze_feedback_submission(submission)
                analyses.append(analysis)
            except Exception as e:
                logger.error(f"Error analyzing submission {submission.get('id')}: {str(e)}")
        
        if not analyses:
            logger.warning(f"Failed to analyze any submissions for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to analyze submissions for feedback ID: {feedback_id}"
            )
        
        # Combine analyses into a single analysis
        combined_analysis = analyses[0]
        
        # Update submission count
        combined_analysis.key_metrics["totalSubmissions"] = len(submissions)
        
        # Ensure all fields have meaningful values
        if not combined_analysis.overall_suggestions:
            combined_analysis.overall_suggestions = [
                "Implement regular team meetings to improve information sharing",
                "Create a centralized documentation system for project updates",
                "Establish clear communication channels for feedback and updates"
            ]
            
        if not combined_analysis.overall_priorities:
            combined_analysis.overall_priorities = [
                {"text": "Improve team communication", "priority": "high", "category": "TEAM_COLLABORATION"},
                {"text": "Enhance documentation processes", "priority": "medium", "category": "DOCUMENTATION"}
            ]
            
        if not combined_analysis.improvement_areas:
            combined_analysis.improvement_areas = [
                {"category": "TEAM_COLLABORATION", "score": 65.0, "suggestions": ["Implement regular team meetings", "Use collaborative tools for real-time communication"]},
                {"category": "DOCUMENTATION", "score": 70.0, "suggestions": ["Create standardized documentation templates", "Establish a central knowledge repository"]}
            ]
            
        # Ensure all question analyses have suggestions and improvement priorities
        for question in combined_analysis.question_analyses:
            if not question.suggestions:
                question.suggestions = [
                    "Implement regular team meetings to improve information sharing",
                    "Create a centralized documentation system for project updates"
                ]
                
            if not question.improvement_priorities:
                question.improvement_priorities = [
                    {"text": "Improve team communication", "priority": "high", "source": "analysis"}
                ]
                
        # Ensure all categories have recommendations
        for category in combined_analysis.categories.values():
            if not category.recommendations:
                category.recommendations = [
                    "Implement regular team meetings to improve information sharing",
                    "Create a centralized documentation system for project updates"
                ]
        
        return combined_analysis
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error analyzing feedback {feedback_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error analyzing feedback: {str(e)}"
        )

@router.get("/api/analysis/satisfaction/{feedback_id}")
@async_timed
async def get_satisfaction_analysis(feedback_id: int):
    """Get satisfaction analysis for a specific feedback"""
    try:
        logger.info(f"Getting satisfaction analysis for feedback ID: {feedback_id}")
        
        # Fetch submissions for this feedback ID
        submissions = await feedback_analyzer.data_service.fetch_submissions_by_feedback_id(feedback_id)
        
        if not submissions:
            logger.warning(f"No submissions found for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=404,
                detail=f"No submissions found for feedback ID: {feedback_id}"
            )
        
        # Analyze each submission
        analyses = []
        for submission in submissions:
            try:
                analysis = await feedback_analyzer.analyze_feedback_submission(submission)
                analyses.append(analysis)
            except Exception as e:
                logger.error(f"Error analyzing submission {submission.get('id')}: {str(e)}")
        
        if not analyses:
            logger.warning(f"Failed to analyze any submissions for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to analyze submissions for feedback ID: {feedback_id}"
            )
        
        # Calculate aggregate satisfaction metrics
        total_satisfaction = sum(analysis.satisfaction_score for analysis in analyses)
        avg_satisfaction = total_satisfaction / len(analyses) if analyses else 0
        
        # Ensure avg_satisfaction is a valid percentage between 0 and 100
        avg_satisfaction = max(0, min(100, avg_satisfaction))
        avg_satisfaction = round(avg_satisfaction, 1)  # Round to 1 decimal place
        
        # Count sentiments across all analyses
        sentiment_counts = {"POSITIVE": 0, "NEUTRAL": 0, "NEGATIVE": 0}
        for analysis in analyses:
            for sentiment, count in analysis.key_metrics.get("sentiment_distribution", {}).items():
                sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + count
        
        # Calculate percentages
        total_sentiments = sum(sentiment_counts.values())
        sentiment_percentages = {}
        if total_sentiments > 0:
            for sentiment, count in sentiment_counts.items():
                percentage = (count / total_sentiments) * 100
                sentiment_percentages[sentiment] = round(percentage, 1)  # Round to 1 decimal place
        else:
            # Default values if no sentiments found
            sentiment_percentages = {
                "POSITIVE": 33.3,
                "NEUTRAL": 33.3,
                "NEGATIVE": 33.3
            }
            
        # Calculate satisfaction rate based on sentiment distribution
        positive_percentage = sentiment_percentages.get("POSITIVE", 0)
        neutral_percentage = sentiment_percentages.get("NEUTRAL", 0)
        
        # Calculate satisfaction rate: 100% of positive + 50% of neutral
        satisfaction_rate = positive_percentage + (neutral_percentage * 0.5)
        satisfaction_rate = round(satisfaction_rate, 1)  # Round to 1 decimal place
        
        # Collect all suggestions
        all_suggestions = []
        for analysis in analyses:
            all_suggestions.extend(analysis.overall_suggestions)
        
        # Remove duplicates and limit to top 5
        unique_suggestions = list(set(all_suggestions))[:5]
        
        # If no suggestions, add default ones
        if not unique_suggestions:
            unique_suggestions = [
                "Implement regular team meetings to improve information sharing",
                "Create a centralized documentation system for project updates",
                "Establish clear communication channels for feedback and updates",
                "Provide more opportunities for professional development",
                "Enhance work-life balance initiatives"
            ]
        
        # Extract satisfaction-specific information
        satisfaction_data = {
            "feedbackId": feedback_id,
            "satisfactionOverview": {
                "overallSatisfaction": avg_satisfaction,
                "satisfactionRate": satisfaction_rate,
                "totalSubmissions": len(submissions)
            },
            "sentimentDistribution": {
                "positive": {
                    "percentage": sentiment_percentages.get("POSITIVE", 0),
                    "emoji": "üòÉ",
                    "label": "Positive"
                },
                "neutral": {
                    "percentage": sentiment_percentages.get("NEUTRAL", 0),
                    "emoji": "üòê",
                    "label": "Neutral"
                },
                "negative": {
                    "percentage": sentiment_percentages.get("NEGATIVE", 0),
                    "emoji": "üòû",
                    "label": "Negative"
                }
            },
            "suggestions": unique_suggestions
        }
        
        return satisfaction_data
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting satisfaction analysis for feedback {feedback_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error getting satisfaction analysis: {str(e)}"
        )

@router.get("/api/analysis/insights/{feedback_id}")
@async_timed
async def get_insights(feedback_id: int):
    """Get AI-powered insights for a specific feedback"""
    try:
        logger.info(f"Getting insights for feedback ID: {feedback_id}")
        
        # Fetch submissions for this feedback ID
        submissions = await feedback_analyzer.data_service.fetch_submissions_by_feedback_id(feedback_id)
        
        if not submissions:
            logger.warning(f"No submissions found for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=404,
                detail=f"No submissions found for feedback ID: {feedback_id}"
            )
        
        # Analyze each submission
        analyses = []
        for submission in submissions:
            try:
                analysis = await feedback_analyzer.analyze_feedback_submission(submission)
                analyses.append(analysis)
            except Exception as e:
                logger.error(f"Error analyzing submission {submission.get('id')}: {str(e)}")
        
        if not analyses:
            logger.warning(f"Failed to analyze any submissions for feedback ID: {feedback_id}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to analyze submissions for feedback ID: {feedback_id}"
            )
        
        # Combine analyses
        combined_analysis = analyses[0]
        
        # Collect all action items and improvement areas
        all_action_items = []
        all_improvement_areas = []
        all_categories = set()
        
        for analysis in analyses:
            all_action_items.extend(analysis.executive_summary.action_items)
            all_improvement_areas.extend(analysis.improvement_areas)
            all_categories.update(analysis.categories.keys())
        
        # Default recommendations if none are found
        default_performance_recommendations = [
            {"text": "Implement regular project status updates to track progress", "priority": "high"},
            {"text": "Establish clear performance metrics for team members", "priority": "medium"},
            {"text": "Provide targeted training for skill development", "priority": "medium"}
        ]
        
        default_engagement_recommendations = [
            {"text": "Schedule regular team-building activities", "priority": "medium"},
            {"text": "Create channels for open communication and feedback", "priority": "high"},
            {"text": "Recognize and reward team achievements", "priority": "medium"}
        ]
        
        default_improvement_recommendations = [
            {"text": "Implement a structured approach to requirements gathering", "priority": "high"},
            {"text": "Establish a knowledge sharing system for the team", "priority": "medium"},
            {"text": "Provide more opportunities for professional development", "priority": "medium"}
        ]
        
        # Generate performance insights
        performance_recommendations = []
        for item in all_action_items:
            if item.get("category") in ["PERFORMANCE", "PROJECT_MANAGEMENT", "TECHNICAL_SKILLS"]:
                performance_recommendations.append({
                    "text": item.get("text"),
                    "priority": item.get("priority", "medium")
                })
        
        # Use default if none found
        if not performance_recommendations:
            performance_recommendations = default_performance_recommendations
        
        # Generate engagement insights
        engagement_recommendations = []
        for item in all_action_items:
            if item.get("category") in ["TEAM_COLLABORATION", "WORK_ENVIRONMENT", "COMMUNICATION"]:
                engagement_recommendations.append({
                    "text": item.get("text"),
                    "priority": item.get("priority", "medium")
                })
        
        # Use default if none found
        if not engagement_recommendations:
            engagement_recommendations = default_engagement_recommendations
        
        # Generate improvement opportunities
        improvement_recommendations = []
        for area in all_improvement_areas:
            suggestions = area.get("suggestions", [])
            if suggestions:
                improvement_recommendations.append({
                    "text": suggestions[0],
                    "priority": "high" if area.get("score", 50) < 40 else "medium"
                })
        
        # Use default if none found
        if not improvement_recommendations:
            improvement_recommendations = default_improvement_recommendations
        
        # Extract insights
        insights = {
            "feedbackId": feedback_id,
            "title": "AI-Powered Insights",
            "description": "Leveraging advanced machine learning algorithms for data-driven recommendations",
            "insights": {
                "performanceInsights": {
                    "title": "Performance Insights",
                    "aiConfidence": 85,
                    "recommendations": performance_recommendations[:3]  # Top 3 recommendations
                },
                "engagementAnalysis": {
                    "title": "Engagement Analysis",
                    "aiConfidence": 80,
                    "recommendations": engagement_recommendations[:3]  # Top 3 recommendations
                },
                "improvementOpportunities": {
                    "title": "Improvement Opportunities",
                    "aiConfidence": 90,
                    "recommendations": improvement_recommendations[:3]  # Top 3 recommendations
                }
            },
            "metadata": {
                "totalSubmissions": len(submissions),
                "analyzedAt": datetime.now().isoformat(),
                "categories": list(all_categories)
            }
        }
        
        return insights
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting insights for feedback {feedback_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error getting insights: {str(e)}"
        ) 